{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6394219",
   "metadata": {},
   "source": [
    "# Customer Segmentation using K-means Clustering\n",
    "\n",
    "Starter notebook template. Replace `OnlineRetail.csv` with your dataset file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc20f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e2feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data: replace the filename with your actual file\n",
    "try:\n",
    "    data = pd.read_csv('OnlineRetail.csv', encoding='ISO-8859-1')\n",
    "except FileNotFoundError:\n",
    "    print('Place your dataset file named OnlineRetail.csv in the same folder as this notebook or change the filename here.')\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "# Show basic info\n",
    "print('Rows, Columns:', data.shape)\n",
    "\n",
    "if not data.empty:\n",
    "    display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1245593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info and missing values\n",
    "if not data.empty:\n",
    "    display(data.info())\n",
    "    display(data.describe(include='all'))\n",
    "    display(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40acfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning steps (examples)\n",
    "if not data.empty:\n",
    "    # Drop rows with no CustomerID\n",
    "    data = data.dropna(subset=['CustomerID'])\n",
    "    # Remove cancelled orders if InvoiceNo starts with 'C'\n",
    "    if 'InvoiceNo' in data.columns:\n",
    "        data = data[~data['InvoiceNo'].astype(str).str.startswith('C')]\n",
    "    # Remove duplicates\n",
    "    data = data.drop_duplicates()\n",
    "    # Correct data types\n",
    "    if 'InvoiceDate' in data.columns:\n",
    "        data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'], errors='coerce')\n",
    "    # Example engineered feature\n",
    "    if {'Quantity','UnitPrice'}.issubset(data.columns):\n",
    "        data['TotalAmount'] = data['Quantity'] * data['UnitPrice']\n",
    "    display(data.head())\n",
    "    print('Cleaned shape:', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53d6db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering / aggregation (example: RFM features)\n",
    "if not data.empty:\n",
    "    # Convert CustomerID to string\n",
    "    data['CustomerID'] = data['CustomerID'].astype(str)\n",
    "    snapshot_date = data['InvoiceDate'].max() + pd.Timedelta(days=1) if 'InvoiceDate' in data.columns and not data['InvoiceDate'].isnull().all() else pd.Timestamp.today()\n",
    "    # Compute RFM\n",
    "    rfm = data.groupby('CustomerID').agg({\n",
    "        'InvoiceDate': lambda x: (snapshot_date - x.max()).days,\n",
    "        'InvoiceNo': 'nunique',\n",
    "        'TotalAmount': 'sum'\n",
    "    }).reset_index()\n",
    "    rfm.columns = ['CustomerID','Recency','Frequency','Monetary']\n",
    "    display(rfm.head())\n",
    "    print('RFM shape:', rfm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87bc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features\n",
    "if 'rfm' in globals() and not rfm.empty:\n",
    "    scaler = StandardScaler()\n",
    "    rfm_scaled = rfm.copy()\n",
    "    rfm_scaled[['Recency','Frequency','Monetary']] = scaler.fit_transform(rfm[['Recency','Frequency','Monetary']])\n",
    "    display(rfm_scaled.head())\n",
    "else:\n",
    "    print('RFM not available to scale (check previous steps)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned and engineered features to CSV\n",
    "output_csv = 'CustomerSegmentation_Features_AdityaRaj.csv'\n",
    "if not data.empty:\n",
    "    # Save RFM if exists, else save cleaned data\n",
    "    if 'rfm' in globals() and not rfm.empty:\n",
    "        rfm.to_csv(output_csv, index=False)\n",
    "        print('Saved RFM features to', output_csv)\n",
    "    else:\n",
    "        data.to_csv('Cleaned_OnlineRetail_AdityaRaj.csv', index=False)\n",
    "        print('Saved cleaned dataset to Cleaned_OnlineRetail_AdityaRaj.csv')\n",
    "else:\n",
    "    print('No data to save.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39fd711",
   "metadata": {},
   "source": [
    "## Notes and Next Steps\n",
    "\n",
    "- Replace placeholder filename with your dataset.\n",
    "- Run cells sequentially, inspect outputs, and modify cleaning rules as needed.\n",
    "- After creating features and scaling, apply K-means from scikit-learn and evaluate using the elbow method and silhouette score.\n",
    "- Before submission: Clear all outputs (Kernel -> Restart & Clear Output) to reduce file size, then save the notebook.\n",
    "- Compress the notebook file if necessary (zip) and ensure file < 10 MB.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
